# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: bareun/language_service.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import enum_type_wrapper
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1d\x62\x61reun/language_service.proto\x12\x06\x62\x61reun\x1a\x1cgoogle/api/annotations.proto\"-\n\x08\x44ocument\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\x12\x10\n\x08language\x18\x04 \x01(\t\"Z\n\x08Sentence\x12\x1e\n\x04text\x18\x01 \x01(\x0b\x32\x10.bareun.TextSpan\x12\x1d\n\x06tokens\x18\x02 \x03(\x0b\x32\r.bareun.Token\x12\x0f\n\x07refined\x18\x03 \x01(\t\"\x95\x05\n\x08Morpheme\x12\x1e\n\x04text\x18\x01 \x01(\x0b\x32\x10.bareun.TextSpan\x12!\n\x03tag\x18\x02 \x01(\x0e\x32\x14.bareun.Morpheme.Tag\x12\x13\n\x0bprobability\x18\x03 \x01(\x02\x12\x31\n\x0cout_of_vocab\x18\x05 \x01(\x0e\x32\x1b.bareun.Morpheme.OutOfVocab\"^\n\nOutOfVocab\x12\x15\n\x11IN_WORD_EMBEDDING\x10\x00\x12\x10\n\x0cOUT_OF_VOCAB\x10\x01\x12\x12\n\x0eIN_CUSTOM_DICT\x10\x02\x12\x13\n\x0fIN_BUILTIN_DICT\x10\x03\"\x9d\x03\n\x03Tag\x12\x07\n\x03UNK\x10\x00\x12\x07\n\x03NNG\x10\x18\x12\x07\n\x03NNP\x10\x19\x12\x07\n\x03NNB\x10\x17\x12\x06\n\x02NP\x10\x1a\x12\x06\n\x02NR\x10\x1b\x12\x06\n\x02NF\x10\x16\x12\x06\n\x02NA\x10\x15\x12\x06\n\x02NV\x10\x1c\x12\x06\n\x02VV\x10)\x12\x06\n\x02VA\x10&\x12\x06\n\x02VX\x10*\x12\x07\n\x03VCP\x10(\x12\x07\n\x03VCN\x10\'\x12\x07\n\x03MMA\x10\x12\x12\x07\n\x03MMD\x10\x13\x12\x07\n\x03MMN\x10\x14\x12\x07\n\x03MAG\x10\x10\x12\x07\n\x03MAJ\x10\x11\x12\x06\n\x02IC\x10\x06\x12\x07\n\x03JKS\x10\r\x12\x07\n\x03JKC\x10\t\x12\x07\n\x03JKG\x10\n\x12\x07\n\x03JKO\x10\x0b\x12\x07\n\x03JKB\x10\x08\x12\x07\n\x03JKV\x10\x0e\x12\x07\n\x03JKQ\x10\x0c\x12\x06\n\x02JX\x10\x0f\x12\x06\n\x02JC\x10\x07\x12\x06\n\x02\x45P\x10\x03\x12\x06\n\x02\x45\x46\x10\x02\x12\x06\n\x02\x45\x43\x10\x01\x12\x07\n\x03\x45TN\x10\x05\x12\x07\n\x03\x45TM\x10\x04\x12\x07\n\x03XPN\x10+\x12\x07\n\x03XSN\x10.\x12\x07\n\x03XSV\x10/\x12\x07\n\x03XSA\x10-\x12\x06\n\x02XR\x10,\x12\x06\n\x02SF\x10\x1e\x12\x06\n\x02SP\x10#\x12\x06\n\x02SS\x10$\x12\x06\n\x02SE\x10\x1d\x12\x06\n\x02SO\x10\"\x12\x06\n\x02SW\x10%\x12\x06\n\x02SL\x10 \x12\x06\n\x02SH\x10\x1f\x12\x06\n\x02SN\x10!\"k\n\x05Token\x12\x1e\n\x04text\x18\x01 \x01(\x0b\x32\x10.bareun.TextSpan\x12#\n\tmorphemes\x18\x02 \x03(\x0b\x32\x10.bareun.Morpheme\x12\r\n\x05lemma\x18\x04 \x01(\t\x12\x0e\n\x06tagged\x18\x05 \x01(\t\"A\n\x08TextSpan\x12\x0f\n\x07\x63ontent\x18\x01 \x01(\t\x12\x14\n\x0c\x62\x65gin_offset\x18\x02 \x01(\x05\x12\x0e\n\x06length\x18\x03 \x01(\x05\"\xc8\x01\n\x14\x41nalyzeSyntaxRequest\x12\"\n\x08\x64ocument\x18\x01 \x01(\x0b\x32\x10.bareun.Document\x12+\n\rencoding_type\x18\x02 \x01(\x0e\x32\x14.bareun.EncodingType\x12\x1b\n\x13\x61uto_split_sentence\x18\x03 \x01(\x08\x12\x15\n\rcustom_domain\x18\x04 \x01(\t\x12\x14\n\x0c\x61uto_spacing\x18\x05 \x01(\x08\x12\x15\n\rauto_jointing\x18\x06 \x01(\x08\"N\n\x15\x41nalyzeSyntaxResponse\x12#\n\tsentences\x18\x01 \x03(\x0b\x32\x10.bareun.Sentence\x12\x10\n\x08language\x18\x03 \x01(\t\"\xb0\x01\n\x18\x41nalyzeSyntaxListRequest\x12\x11\n\tsentences\x18\x01 \x03(\t\x12\x10\n\x08language\x18\x02 \x01(\t\x12+\n\rencoding_type\x18\x03 \x01(\x0e\x32\x14.bareun.EncodingType\x12\x15\n\rcustom_domain\x18\x04 \x01(\t\x12\x14\n\x0c\x61uto_spacing\x18\x05 \x01(\x08\x12\x15\n\rauto_jointing\x18\x06 \x01(\x08\"R\n\x19\x41nalyzeSyntaxListResponse\x12#\n\tsentences\x18\x01 \x03(\x0b\x32\x10.bareun.Sentence\x12\x10\n\x08language\x18\x03 \x01(\t\"\x95\x01\n\x0fTokenizeRequest\x12\"\n\x08\x64ocument\x18\x01 \x01(\x0b\x32\x10.bareun.Document\x12+\n\rencoding_type\x18\x02 \x01(\x0e\x32\x14.bareun.EncodingType\x12\x1b\n\x13\x61uto_split_sentence\x18\x03 \x01(\x08\x12\x14\n\x0c\x61uto_spacing\x18\x05 \x01(\x08\"7\n\x07Segment\x12\x1e\n\x04text\x18\x01 \x01(\x0b\x32\x10.bareun.TextSpan\x12\x0c\n\x04hint\x18\x02 \x01(\t\"a\n\x0cSegmentToken\x12\x1e\n\x04text\x18\x01 \x01(\x0b\x32\x10.bareun.TextSpan\x12!\n\x08segments\x18\x02 \x03(\x0b\x32\x0f.bareun.Segment\x12\x0e\n\x06tagged\x18\x05 \x01(\t\"J\n\x10TokenizeResponse\x12$\n\x06tokens\x18\x01 \x03(\x0b\x32\x14.bareun.SegmentToken\x12\x10\n\x08language\x18\x03 \x01(\t*8\n\x0c\x45ncodingType\x12\x08\n\x04NONE\x10\x00\x12\x08\n\x04UTF8\x10\x01\x12\t\n\x05UTF16\x10\x02\x12\t\n\x05UTF32\x10\x03\x32\xe8\x02\n\x0fLanguageService\x12o\n\rAnalyzeSyntax\x12\x1c.bareun.AnalyzeSyntaxRequest\x1a\x1d.bareun.AnalyzeSyntaxResponse\"!\x82\xd3\xe4\x93\x02\x1b\"\x16/bareun/api/v1/analyze:\x01*\x12\x80\x01\n\x11\x41nalyzeSyntaxList\x12 .bareun.AnalyzeSyntaxListRequest\x1a!.bareun.AnalyzeSyntaxListResponse\"&\x82\xd3\xe4\x93\x02 \"\x1b/bareun/api/v1/analyze-list:\x01*\x12\x61\n\x08Tokenize\x12\x17.bareun.TokenizeRequest\x1a\x18.bareun.TokenizeResponse\"\"\x82\xd3\xe4\x93\x02\x1c\"\x17/bareun/api/v1/tokenize:\x01*B;\n\tbareun.aiB\x14LanguageServiceProtoP\x01Z\x16\x62\x61reun.ai/proto/bareunb\x06proto3')

_ENCODINGTYPE = DESCRIPTOR.enum_types_by_name['EncodingType']
EncodingType = enum_type_wrapper.EnumTypeWrapper(_ENCODINGTYPE)
NONE = 0
UTF8 = 1
UTF16 = 2
UTF32 = 3


_DOCUMENT = DESCRIPTOR.message_types_by_name['Document']
_SENTENCE = DESCRIPTOR.message_types_by_name['Sentence']
_MORPHEME = DESCRIPTOR.message_types_by_name['Morpheme']
_TOKEN = DESCRIPTOR.message_types_by_name['Token']
_TEXTSPAN = DESCRIPTOR.message_types_by_name['TextSpan']
_ANALYZESYNTAXREQUEST = DESCRIPTOR.message_types_by_name['AnalyzeSyntaxRequest']
_ANALYZESYNTAXRESPONSE = DESCRIPTOR.message_types_by_name['AnalyzeSyntaxResponse']
_ANALYZESYNTAXLISTREQUEST = DESCRIPTOR.message_types_by_name['AnalyzeSyntaxListRequest']
_ANALYZESYNTAXLISTRESPONSE = DESCRIPTOR.message_types_by_name['AnalyzeSyntaxListResponse']
_TOKENIZEREQUEST = DESCRIPTOR.message_types_by_name['TokenizeRequest']
_SEGMENT = DESCRIPTOR.message_types_by_name['Segment']
_SEGMENTTOKEN = DESCRIPTOR.message_types_by_name['SegmentToken']
_TOKENIZERESPONSE = DESCRIPTOR.message_types_by_name['TokenizeResponse']
_MORPHEME_OUTOFVOCAB = _MORPHEME.enum_types_by_name['OutOfVocab']
_MORPHEME_TAG = _MORPHEME.enum_types_by_name['Tag']
Document = _reflection.GeneratedProtocolMessageType('Document', (_message.Message,), {
  'DESCRIPTOR' : _DOCUMENT,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.Document)
  })
_sym_db.RegisterMessage(Document)

Sentence = _reflection.GeneratedProtocolMessageType('Sentence', (_message.Message,), {
  'DESCRIPTOR' : _SENTENCE,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.Sentence)
  })
_sym_db.RegisterMessage(Sentence)

Morpheme = _reflection.GeneratedProtocolMessageType('Morpheme', (_message.Message,), {
  'DESCRIPTOR' : _MORPHEME,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.Morpheme)
  })
_sym_db.RegisterMessage(Morpheme)

Token = _reflection.GeneratedProtocolMessageType('Token', (_message.Message,), {
  'DESCRIPTOR' : _TOKEN,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.Token)
  })
_sym_db.RegisterMessage(Token)

TextSpan = _reflection.GeneratedProtocolMessageType('TextSpan', (_message.Message,), {
  'DESCRIPTOR' : _TEXTSPAN,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.TextSpan)
  })
_sym_db.RegisterMessage(TextSpan)

AnalyzeSyntaxRequest = _reflection.GeneratedProtocolMessageType('AnalyzeSyntaxRequest', (_message.Message,), {
  'DESCRIPTOR' : _ANALYZESYNTAXREQUEST,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.AnalyzeSyntaxRequest)
  })
_sym_db.RegisterMessage(AnalyzeSyntaxRequest)

AnalyzeSyntaxResponse = _reflection.GeneratedProtocolMessageType('AnalyzeSyntaxResponse', (_message.Message,), {
  'DESCRIPTOR' : _ANALYZESYNTAXRESPONSE,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.AnalyzeSyntaxResponse)
  })
_sym_db.RegisterMessage(AnalyzeSyntaxResponse)

AnalyzeSyntaxListRequest = _reflection.GeneratedProtocolMessageType('AnalyzeSyntaxListRequest', (_message.Message,), {
  'DESCRIPTOR' : _ANALYZESYNTAXLISTREQUEST,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.AnalyzeSyntaxListRequest)
  })
_sym_db.RegisterMessage(AnalyzeSyntaxListRequest)

AnalyzeSyntaxListResponse = _reflection.GeneratedProtocolMessageType('AnalyzeSyntaxListResponse', (_message.Message,), {
  'DESCRIPTOR' : _ANALYZESYNTAXLISTRESPONSE,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.AnalyzeSyntaxListResponse)
  })
_sym_db.RegisterMessage(AnalyzeSyntaxListResponse)

TokenizeRequest = _reflection.GeneratedProtocolMessageType('TokenizeRequest', (_message.Message,), {
  'DESCRIPTOR' : _TOKENIZEREQUEST,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.TokenizeRequest)
  })
_sym_db.RegisterMessage(TokenizeRequest)

Segment = _reflection.GeneratedProtocolMessageType('Segment', (_message.Message,), {
  'DESCRIPTOR' : _SEGMENT,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.Segment)
  })
_sym_db.RegisterMessage(Segment)

SegmentToken = _reflection.GeneratedProtocolMessageType('SegmentToken', (_message.Message,), {
  'DESCRIPTOR' : _SEGMENTTOKEN,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.SegmentToken)
  })
_sym_db.RegisterMessage(SegmentToken)

TokenizeResponse = _reflection.GeneratedProtocolMessageType('TokenizeResponse', (_message.Message,), {
  'DESCRIPTOR' : _TOKENIZERESPONSE,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.TokenizeResponse)
  })
_sym_db.RegisterMessage(TokenizeResponse)

_LANGUAGESERVICE = DESCRIPTOR.services_by_name['LanguageService']
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'\n\tbareun.aiB\024LanguageServiceProtoP\001Z\026bareun.ai/proto/bareun'
  _LANGUAGESERVICE.methods_by_name['AnalyzeSyntax']._options = None
  _LANGUAGESERVICE.methods_by_name['AnalyzeSyntax']._serialized_options = b'\202\323\344\223\002\033\"\026/bareun/api/v1/analyze:\001*'
  _LANGUAGESERVICE.methods_by_name['AnalyzeSyntaxList']._options = None
  _LANGUAGESERVICE.methods_by_name['AnalyzeSyntaxList']._serialized_options = b'\202\323\344\223\002 \"\033/bareun/api/v1/analyze-list:\001*'
  _LANGUAGESERVICE.methods_by_name['Tokenize']._options = None
  _LANGUAGESERVICE.methods_by_name['Tokenize']._serialized_options = b'\202\323\344\223\002\034\"\027/bareun/api/v1/tokenize:\001*'
  _ENCODINGTYPE._serialized_start=1980
  _ENCODINGTYPE._serialized_end=2036
  _DOCUMENT._serialized_start=71
  _DOCUMENT._serialized_end=116
  _SENTENCE._serialized_start=118
  _SENTENCE._serialized_end=208
  _MORPHEME._serialized_start=211
  _MORPHEME._serialized_end=872
  _MORPHEME_OUTOFVOCAB._serialized_start=362
  _MORPHEME_OUTOFVOCAB._serialized_end=456
  _MORPHEME_TAG._serialized_start=459
  _MORPHEME_TAG._serialized_end=872
  _TOKEN._serialized_start=874
  _TOKEN._serialized_end=981
  _TEXTSPAN._serialized_start=983
  _TEXTSPAN._serialized_end=1048
  _ANALYZESYNTAXREQUEST._serialized_start=1051
  _ANALYZESYNTAXREQUEST._serialized_end=1251
  _ANALYZESYNTAXRESPONSE._serialized_start=1253
  _ANALYZESYNTAXRESPONSE._serialized_end=1331
  _ANALYZESYNTAXLISTREQUEST._serialized_start=1334
  _ANALYZESYNTAXLISTREQUEST._serialized_end=1510
  _ANALYZESYNTAXLISTRESPONSE._serialized_start=1512
  _ANALYZESYNTAXLISTRESPONSE._serialized_end=1594
  _TOKENIZEREQUEST._serialized_start=1597
  _TOKENIZEREQUEST._serialized_end=1746
  _SEGMENT._serialized_start=1748
  _SEGMENT._serialized_end=1803
  _SEGMENTTOKEN._serialized_start=1805
  _SEGMENTTOKEN._serialized_end=1902
  _TOKENIZERESPONSE._serialized_start=1904
  _TOKENIZERESPONSE._serialized_end=1978
  _LANGUAGESERVICE._serialized_start=2039
  _LANGUAGESERVICE._serialized_end=2399
# @@protoc_insertion_point(module_scope)

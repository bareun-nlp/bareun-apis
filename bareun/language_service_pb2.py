# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: bareun/language_service.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2
from bareun import lang_common_pb2 as bareun_dot_lang__common__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1d\x62\x61reun/language_service.proto\x12\x06\x62\x61reun\x1a\x1cgoogle/api/annotations.proto\x1a\x18\x62\x61reun/lang_common.proto\"Z\n\x08Sentence\x12\x1e\n\x04text\x18\x01 \x01(\x0b\x32\x10.bareun.TextSpan\x12\x1d\n\x06tokens\x18\x02 \x03(\x0b\x32\r.bareun.Token\x12\x0f\n\x07refined\x18\x03 \x01(\t\"\xc9\x05\n\x08Morpheme\x12\x1e\n\x04text\x18\x01 \x01(\x0b\x32\x10.bareun.TextSpan\x12!\n\x03tag\x18\x02 \x01(\x0e\x32\x14.bareun.Morpheme.Tag\x12\x13\n\x0bprobability\x18\x03 \x01(\x02\x12\x31\n\x0cout_of_vocab\x18\x05 \x01(\x0e\x32\x1b.bareun.Morpheme.OutOfVocab\x12\x1d\n\x10\x63ustom_dict_name\x18\x06 \x01(\tH\x00\x88\x01\x01\"^\n\nOutOfVocab\x12\x15\n\x11IN_WORD_EMBEDDING\x10\x00\x12\x10\n\x0cOUT_OF_VOCAB\x10\x01\x12\x12\n\x0eIN_CUSTOM_DICT\x10\x02\x12\x13\n\x0fIN_BUILTIN_DICT\x10\x03\"\x9d\x03\n\x03Tag\x12\x07\n\x03UNK\x10\x00\x12\x07\n\x03NNG\x10\x18\x12\x07\n\x03NNP\x10\x19\x12\x07\n\x03NNB\x10\x17\x12\x06\n\x02NP\x10\x1a\x12\x06\n\x02NR\x10\x1b\x12\x06\n\x02NF\x10\x16\x12\x06\n\x02NA\x10\x15\x12\x06\n\x02NV\x10\x1c\x12\x06\n\x02VV\x10)\x12\x06\n\x02VA\x10&\x12\x06\n\x02VX\x10*\x12\x07\n\x03VCP\x10(\x12\x07\n\x03VCN\x10\'\x12\x07\n\x03MMA\x10\x12\x12\x07\n\x03MMD\x10\x13\x12\x07\n\x03MMN\x10\x14\x12\x07\n\x03MAG\x10\x10\x12\x07\n\x03MAJ\x10\x11\x12\x06\n\x02IC\x10\x06\x12\x07\n\x03JKS\x10\r\x12\x07\n\x03JKC\x10\t\x12\x07\n\x03JKG\x10\n\x12\x07\n\x03JKO\x10\x0b\x12\x07\n\x03JKB\x10\x08\x12\x07\n\x03JKV\x10\x0e\x12\x07\n\x03JKQ\x10\x0c\x12\x06\n\x02JX\x10\x0f\x12\x06\n\x02JC\x10\x07\x12\x06\n\x02\x45P\x10\x03\x12\x06\n\x02\x45\x46\x10\x02\x12\x06\n\x02\x45\x43\x10\x01\x12\x07\n\x03\x45TN\x10\x05\x12\x07\n\x03\x45TM\x10\x04\x12\x07\n\x03XPN\x10+\x12\x07\n\x03XSN\x10.\x12\x07\n\x03XSV\x10/\x12\x07\n\x03XSA\x10-\x12\x06\n\x02XR\x10,\x12\x06\n\x02SF\x10\x1e\x12\x06\n\x02SP\x10#\x12\x06\n\x02SS\x10$\x12\x06\n\x02SE\x10\x1d\x12\x06\n\x02SO\x10\"\x12\x06\n\x02SW\x10%\x12\x06\n\x02SL\x10 \x12\x06\n\x02SH\x10\x1f\x12\x06\n\x02SN\x10!B\x13\n\x11_custom_dict_name\"}\n\x05Token\x12\x1e\n\x04text\x18\x01 \x01(\x0b\x32\x10.bareun.TextSpan\x12#\n\tmorphemes\x18\x02 \x03(\x0b\x32\x10.bareun.Morpheme\x12\r\n\x05lemma\x18\x04 \x01(\t\x12\x0e\n\x06tagged\x18\x05 \x01(\t\x12\x10\n\x08modified\x18\x0b \x01(\t\"\xe7\x01\n\x14\x41nalyzeSyntaxRequest\x12\"\n\x08\x64ocument\x18\x01 \x01(\x0b\x32\x10.bareun.Document\x12+\n\rencoding_type\x18\x02 \x01(\x0e\x32\x14.bareun.EncodingType\x12\x1b\n\x13\x61uto_split_sentence\x18\x03 \x01(\x08\x12\x19\n\rcustom_domain\x18\x04 \x01(\tB\x02\x18\x01\x12\x14\n\x0c\x61uto_spacing\x18\x05 \x01(\x08\x12\x15\n\rauto_jointing\x18\x06 \x01(\x08\x12\x19\n\x11\x63ustom_dict_names\x18\x0b \x03(\t\"N\n\x15\x41nalyzeSyntaxResponse\x12#\n\tsentences\x18\x01 \x03(\x0b\x32\x10.bareun.Sentence\x12\x10\n\x08language\x18\x03 \x01(\t\"\xcf\x01\n\x18\x41nalyzeSyntaxListRequest\x12\x11\n\tsentences\x18\x01 \x03(\t\x12\x10\n\x08language\x18\x02 \x01(\t\x12+\n\rencoding_type\x18\x03 \x01(\x0e\x32\x14.bareun.EncodingType\x12\x19\n\rcustom_domain\x18\x04 \x01(\tB\x02\x18\x01\x12\x14\n\x0c\x61uto_spacing\x18\x05 \x01(\x08\x12\x15\n\rauto_jointing\x18\x06 \x01(\x08\x12\x19\n\x11\x63ustom_dict_names\x18\x0b \x03(\t\"R\n\x19\x41nalyzeSyntaxListResponse\x12#\n\tsentences\x18\x01 \x03(\x0b\x32\x10.bareun.Sentence\x12\x10\n\x08language\x18\x03 \x01(\t\"\x95\x01\n\x0fTokenizeRequest\x12\"\n\x08\x64ocument\x18\x01 \x01(\x0b\x32\x10.bareun.Document\x12+\n\rencoding_type\x18\x02 \x01(\x0e\x32\x14.bareun.EncodingType\x12\x1b\n\x13\x61uto_split_sentence\x18\x03 \x01(\x08\x12\x14\n\x0c\x61uto_spacing\x18\x05 \x01(\x08\"7\n\x07Segment\x12\x1e\n\x04text\x18\x01 \x01(\x0b\x32\x10.bareun.TextSpan\x12\x0c\n\x04hint\x18\x02 \x01(\t\"a\n\x0cSegmentToken\x12\x1e\n\x04text\x18\x01 \x01(\x0b\x32\x10.bareun.TextSpan\x12!\n\x08segments\x18\x02 \x03(\x0b\x32\x0f.bareun.Segment\x12\x0e\n\x06tagged\x18\x05 \x01(\t\"W\n\x0fSegmentSentence\x12\x1e\n\x04text\x18\x01 \x01(\x0b\x32\x10.bareun.TextSpan\x12$\n\x06tokens\x18\x02 \x03(\x0b\x32\x14.bareun.SegmentToken\"P\n\x10TokenizeResponse\x12*\n\tsentences\x18\x01 \x03(\x0b\x32\x17.bareun.SegmentSentence\x12\x10\n\x08language\x18\x03 \x01(\t2\xe8\x02\n\x0fLanguageService\x12o\n\rAnalyzeSyntax\x12\x1c.bareun.AnalyzeSyntaxRequest\x1a\x1d.bareun.AnalyzeSyntaxResponse\"!\x82\xd3\xe4\x93\x02\x1b\"\x16/bareun/api/v1/analyze:\x01*\x12\x80\x01\n\x11\x41nalyzeSyntaxList\x12 .bareun.AnalyzeSyntaxListRequest\x1a!.bareun.AnalyzeSyntaxListResponse\"&\x82\xd3\xe4\x93\x02 \"\x1b/bareun/api/v1/analyze-list:\x01*\x12\x61\n\x08Tokenize\x12\x17.bareun.TokenizeRequest\x1a\x18.bareun.TokenizeResponse\"\"\x82\xd3\xe4\x93\x02\x1c\"\x17/bareun/api/v1/tokenize:\x01*BB\n\x10\x61i.bareun.protosB\x14LanguageServiceProtoP\x01Z\x16\x62\x61reun.ai/proto/bareunb\x06proto3')



_SENTENCE = DESCRIPTOR.message_types_by_name['Sentence']
_MORPHEME = DESCRIPTOR.message_types_by_name['Morpheme']
_TOKEN = DESCRIPTOR.message_types_by_name['Token']
_ANALYZESYNTAXREQUEST = DESCRIPTOR.message_types_by_name['AnalyzeSyntaxRequest']
_ANALYZESYNTAXRESPONSE = DESCRIPTOR.message_types_by_name['AnalyzeSyntaxResponse']
_ANALYZESYNTAXLISTREQUEST = DESCRIPTOR.message_types_by_name['AnalyzeSyntaxListRequest']
_ANALYZESYNTAXLISTRESPONSE = DESCRIPTOR.message_types_by_name['AnalyzeSyntaxListResponse']
_TOKENIZEREQUEST = DESCRIPTOR.message_types_by_name['TokenizeRequest']
_SEGMENT = DESCRIPTOR.message_types_by_name['Segment']
_SEGMENTTOKEN = DESCRIPTOR.message_types_by_name['SegmentToken']
_SEGMENTSENTENCE = DESCRIPTOR.message_types_by_name['SegmentSentence']
_TOKENIZERESPONSE = DESCRIPTOR.message_types_by_name['TokenizeResponse']
_MORPHEME_OUTOFVOCAB = _MORPHEME.enum_types_by_name['OutOfVocab']
_MORPHEME_TAG = _MORPHEME.enum_types_by_name['Tag']
Sentence = _reflection.GeneratedProtocolMessageType('Sentence', (_message.Message,), {
  'DESCRIPTOR' : _SENTENCE,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.Sentence)
  })
_sym_db.RegisterMessage(Sentence)

Morpheme = _reflection.GeneratedProtocolMessageType('Morpheme', (_message.Message,), {
  'DESCRIPTOR' : _MORPHEME,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.Morpheme)
  })
_sym_db.RegisterMessage(Morpheme)

Token = _reflection.GeneratedProtocolMessageType('Token', (_message.Message,), {
  'DESCRIPTOR' : _TOKEN,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.Token)
  })
_sym_db.RegisterMessage(Token)

AnalyzeSyntaxRequest = _reflection.GeneratedProtocolMessageType('AnalyzeSyntaxRequest', (_message.Message,), {
  'DESCRIPTOR' : _ANALYZESYNTAXREQUEST,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.AnalyzeSyntaxRequest)
  })
_sym_db.RegisterMessage(AnalyzeSyntaxRequest)

AnalyzeSyntaxResponse = _reflection.GeneratedProtocolMessageType('AnalyzeSyntaxResponse', (_message.Message,), {
  'DESCRIPTOR' : _ANALYZESYNTAXRESPONSE,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.AnalyzeSyntaxResponse)
  })
_sym_db.RegisterMessage(AnalyzeSyntaxResponse)

AnalyzeSyntaxListRequest = _reflection.GeneratedProtocolMessageType('AnalyzeSyntaxListRequest', (_message.Message,), {
  'DESCRIPTOR' : _ANALYZESYNTAXLISTREQUEST,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.AnalyzeSyntaxListRequest)
  })
_sym_db.RegisterMessage(AnalyzeSyntaxListRequest)

AnalyzeSyntaxListResponse = _reflection.GeneratedProtocolMessageType('AnalyzeSyntaxListResponse', (_message.Message,), {
  'DESCRIPTOR' : _ANALYZESYNTAXLISTRESPONSE,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.AnalyzeSyntaxListResponse)
  })
_sym_db.RegisterMessage(AnalyzeSyntaxListResponse)

TokenizeRequest = _reflection.GeneratedProtocolMessageType('TokenizeRequest', (_message.Message,), {
  'DESCRIPTOR' : _TOKENIZEREQUEST,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.TokenizeRequest)
  })
_sym_db.RegisterMessage(TokenizeRequest)

Segment = _reflection.GeneratedProtocolMessageType('Segment', (_message.Message,), {
  'DESCRIPTOR' : _SEGMENT,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.Segment)
  })
_sym_db.RegisterMessage(Segment)

SegmentToken = _reflection.GeneratedProtocolMessageType('SegmentToken', (_message.Message,), {
  'DESCRIPTOR' : _SEGMENTTOKEN,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.SegmentToken)
  })
_sym_db.RegisterMessage(SegmentToken)

SegmentSentence = _reflection.GeneratedProtocolMessageType('SegmentSentence', (_message.Message,), {
  'DESCRIPTOR' : _SEGMENTSENTENCE,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.SegmentSentence)
  })
_sym_db.RegisterMessage(SegmentSentence)

TokenizeResponse = _reflection.GeneratedProtocolMessageType('TokenizeResponse', (_message.Message,), {
  'DESCRIPTOR' : _TOKENIZERESPONSE,
  '__module__' : 'bareun.language_service_pb2'
  # @@protoc_insertion_point(class_scope:bareun.TokenizeResponse)
  })
_sym_db.RegisterMessage(TokenizeResponse)

_LANGUAGESERVICE = DESCRIPTOR.services_by_name['LanguageService']
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'\n\020ai.bareun.protosB\024LanguageServiceProtoP\001Z\026bareun.ai/proto/bareun'
  _ANALYZESYNTAXREQUEST.fields_by_name['custom_domain']._options = None
  _ANALYZESYNTAXREQUEST.fields_by_name['custom_domain']._serialized_options = b'\030\001'
  _ANALYZESYNTAXLISTREQUEST.fields_by_name['custom_domain']._options = None
  _ANALYZESYNTAXLISTREQUEST.fields_by_name['custom_domain']._serialized_options = b'\030\001'
  _LANGUAGESERVICE.methods_by_name['AnalyzeSyntax']._options = None
  _LANGUAGESERVICE.methods_by_name['AnalyzeSyntax']._serialized_options = b'\202\323\344\223\002\033\"\026/bareun/api/v1/analyze:\001*'
  _LANGUAGESERVICE.methods_by_name['AnalyzeSyntaxList']._options = None
  _LANGUAGESERVICE.methods_by_name['AnalyzeSyntaxList']._serialized_options = b'\202\323\344\223\002 \"\033/bareun/api/v1/analyze-list:\001*'
  _LANGUAGESERVICE.methods_by_name['Tokenize']._options = None
  _LANGUAGESERVICE.methods_by_name['Tokenize']._serialized_options = b'\202\323\344\223\002\034\"\027/bareun/api/v1/tokenize:\001*'
  _SENTENCE._serialized_start=97
  _SENTENCE._serialized_end=187
  _MORPHEME._serialized_start=190
  _MORPHEME._serialized_end=903
  _MORPHEME_OUTOFVOCAB._serialized_start=372
  _MORPHEME_OUTOFVOCAB._serialized_end=466
  _MORPHEME_TAG._serialized_start=469
  _MORPHEME_TAG._serialized_end=882
  _TOKEN._serialized_start=905
  _TOKEN._serialized_end=1030
  _ANALYZESYNTAXREQUEST._serialized_start=1033
  _ANALYZESYNTAXREQUEST._serialized_end=1264
  _ANALYZESYNTAXRESPONSE._serialized_start=1266
  _ANALYZESYNTAXRESPONSE._serialized_end=1344
  _ANALYZESYNTAXLISTREQUEST._serialized_start=1347
  _ANALYZESYNTAXLISTREQUEST._serialized_end=1554
  _ANALYZESYNTAXLISTRESPONSE._serialized_start=1556
  _ANALYZESYNTAXLISTRESPONSE._serialized_end=1638
  _TOKENIZEREQUEST._serialized_start=1641
  _TOKENIZEREQUEST._serialized_end=1790
  _SEGMENT._serialized_start=1792
  _SEGMENT._serialized_end=1847
  _SEGMENTTOKEN._serialized_start=1849
  _SEGMENTTOKEN._serialized_end=1946
  _SEGMENTSENTENCE._serialized_start=1948
  _SEGMENTSENTENCE._serialized_end=2035
  _TOKENIZERESPONSE._serialized_start=2037
  _TOKENIZERESPONSE._serialized_end=2117
  _LANGUAGESERVICE._serialized_start=2120
  _LANGUAGESERVICE._serialized_end=2480
# @@protoc_insertion_point(module_scope)

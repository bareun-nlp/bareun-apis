"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
Copyright 2019-2023 BAIKAL AI Inc."""
import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import sys
import typing

if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _EncodingType:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _EncodingTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_EncodingType.ValueType], builtins.type):  # noqa: F821
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    NONE: _EncodingType.ValueType  # 0
    """If `EncodingType` is not specified, encoding-dependent information (such as
    `begin_offset`) will be set at `-1`.
    """
    UTF8: _EncodingType.ValueType  # 1
    """Encoding-dependent information (such as `begin_offset`) is calculated based
    on the UTF-8 encoding of the input. C++ and Go are examples of languages
    that use this encoding natively.
    """
    UTF16: _EncodingType.ValueType  # 2
    """Encoding-dependent information (such as `begin_offset`) is calculated based
    on the UTF-16 encoding of the input. Java and JavaScript are examples of
    languages that use this encoding natively.
    """
    UTF32: _EncodingType.ValueType  # 3
    """Encoding-dependent information (such as `begin_offset`) is calculated based
    on the UTF-32 encoding of the input. Python is an example of a language
    that uses this encoding natively.
    """

class EncodingType(_EncodingType, metaclass=_EncodingTypeEnumTypeWrapper):
    """Represents the text encoding that the caller uses to process the output.
    Providing an `EncodingType` is recommended because the API provides the
    beginning offsets for various outputs, such as tokens and mentions, and
    languages that natively use different text encodings may access offsets
    differently.
    """

NONE: EncodingType.ValueType  # 0
"""If `EncodingType` is not specified, encoding-dependent information (such as
`begin_offset`) will be set at `-1`.
"""
UTF8: EncodingType.ValueType  # 1
"""Encoding-dependent information (such as `begin_offset`) is calculated based
on the UTF-8 encoding of the input. C++ and Go are examples of languages
that use this encoding natively.
"""
UTF16: EncodingType.ValueType  # 2
"""Encoding-dependent information (such as `begin_offset`) is calculated based
on the UTF-16 encoding of the input. Java and JavaScript are examples of
languages that use this encoding natively.
"""
UTF32: EncodingType.ValueType  # 3
"""Encoding-dependent information (such as `begin_offset`) is calculated based
on the UTF-32 encoding of the input. Python is an example of a language
that uses this encoding natively.
"""
global___EncodingType = EncodingType

class Document(google.protobuf.message.Message):
    """################################################################ #

    Represents the input to API methods.
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    CONTENT_FIELD_NUMBER: builtins.int
    LANGUAGE_FIELD_NUMBER: builtins.int
    content: builtins.str
    """입력 전체의 내용
    여러 문장이 입력되면 "\\n"을 넣어준다.
    """
    language: builtins.str
    """문서의 언어. 현재는 ko_KR 만 지원한다."""
    def __init__(
        self,
        *,
        content: builtins.str = ...,
        language: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["content", b"content", "language", b"language"]) -> None: ...

global___Document = Document

class Sentence(google.protobuf.message.Message):
    """입력 문서에 분석된 문장"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TEXT_FIELD_NUMBER: builtins.int
    TOKENS_FIELD_NUMBER: builtins.int
    REFINED_FIELD_NUMBER: builtins.int
    @property
    def text(self) -> global___TextSpan:
        """The sentence text."""
    @property
    def tokens(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Token]:
        """어절단위로 쪼개는 것은"""
    refined: builtins.str
    """띄어쓰기 등의 오류를 수정한 결과물"""
    def __init__(
        self,
        *,
        text: global___TextSpan | None = ...,
        tokens: collections.abc.Iterable[global___Token] | None = ...,
        refined: builtins.str = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["text", b"text"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["refined", b"refined", "text", b"text", "tokens", b"tokens"]) -> None: ...

global___Sentence = Sentence

class Morpheme(google.protobuf.message.Message):
    """형태소"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    class _OutOfVocab:
        ValueType = typing.NewType("ValueType", builtins.int)
        V: typing_extensions.TypeAlias = ValueType

    class _OutOfVocabEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[Morpheme._OutOfVocab.ValueType], builtins.type):  # noqa: F821
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        IN_WORD_EMBEDDING: Morpheme._OutOfVocab.ValueType  # 0
        """워드 임베딩에 포함된 내용"""
        OUT_OF_VOCAB: Morpheme._OutOfVocab.ValueType  # 1
        """자동 추측, 미등록 단어"""
        IN_CUSTOM_DICT: Morpheme._OutOfVocab.ValueType  # 2
        """사용자 제공 사전에 있는 내용"""
        IN_BUILTIN_DICT: Morpheme._OutOfVocab.ValueType  # 3
        """기본 사전에 포함된 내용"""

    class OutOfVocab(_OutOfVocab, metaclass=_OutOfVocabEnumTypeWrapper):
        """사전에 없는 단어 정보 처리 결과"""

    IN_WORD_EMBEDDING: Morpheme.OutOfVocab.ValueType  # 0
    """워드 임베딩에 포함된 내용"""
    OUT_OF_VOCAB: Morpheme.OutOfVocab.ValueType  # 1
    """자동 추측, 미등록 단어"""
    IN_CUSTOM_DICT: Morpheme.OutOfVocab.ValueType  # 2
    """사용자 제공 사전에 있는 내용"""
    IN_BUILTIN_DICT: Morpheme.OutOfVocab.ValueType  # 3
    """기본 사전에 포함된 내용"""

    class _Tag:
        ValueType = typing.NewType("ValueType", builtins.int)
        V: typing_extensions.TypeAlias = ValueType

    class _TagEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[Morpheme._Tag.ValueType], builtins.type):  # noqa: F821
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        UNK: Morpheme._Tag.ValueType  # 0
        """// 0 1 EC
        // 1 2 EF
        // 2 3 EP
        // 3 4 ETM
        // 4 5 ETN
        // 5 6 IC
        // 6 7 JC
        // 7 8 JKB
        // 8 9 JKC
        // 9 10 JKG
        // 10 11 JKO
        // 11 12 JKQ
        // 12 13 JKS
        // 13 14 JKV
        // 14 15 JX
        // 15 16 MAG
        // 16 17 MAJ
        // 17 18 MMA
        // 18 19 MMD
        // 19 20 MMN
        // 20 21 NA
        // 21 22 NF
        // 22 23 NNB
        // 23 24 NNG
        // 24 25 NNP
        // 25 26 NP
        // 26 27 NR
        // 27 28 NV
        // 28 29 SE
        // 29 30 SF
        // 30 31 SH
        // 31 32 SL
        // 32 33 SN
        // 33 34 SO
        // 34 35 SP
        // 35 36 SS
        // 36 37 SW
        // 37 38 VA
        // 38 39 VCN
        // 39 40 VCP
        // 40 41 VV
        // 41 42 VX
        // 42 43 XPN
        // 43 44 XR
        // 44 45 XSA
        // 45 46 XSN
        // 46 47 XSV
        """
        NNG: Morpheme._Tag.ValueType  # 24
        """일반 명사"""
        NNP: Morpheme._Tag.ValueType  # 25
        """고유 명사"""
        NNB: Morpheme._Tag.ValueType  # 23
        """의존 명사"""
        NP: Morpheme._Tag.ValueType  # 26
        """대명사"""
        NR: Morpheme._Tag.ValueType  # 27
        """수사"""
        NF: Morpheme._Tag.ValueType  # 22
        """명사 추정 범주"""
        NA: Morpheme._Tag.ValueType  # 21
        """분석불능범주"""
        NV: Morpheme._Tag.ValueType  # 28
        """용언 추정 범주"""
        VV: Morpheme._Tag.ValueType  # 41
        """동사"""
        VA: Morpheme._Tag.ValueType  # 38
        """형용사"""
        VX: Morpheme._Tag.ValueType  # 42
        """보조 용언"""
        VCP: Morpheme._Tag.ValueType  # 40
        """긍정 지정사"""
        VCN: Morpheme._Tag.ValueType  # 39
        """부정 지정사"""
        MMA: Morpheme._Tag.ValueType  # 18
        """성상 관형사"""
        MMD: Morpheme._Tag.ValueType  # 19
        """지시 관형사"""
        MMN: Morpheme._Tag.ValueType  # 20
        """수 관형사"""
        MAG: Morpheme._Tag.ValueType  # 16
        """일반 부사"""
        MAJ: Morpheme._Tag.ValueType  # 17
        """접속 부사"""
        IC: Morpheme._Tag.ValueType  # 6
        """감탄사"""
        JKS: Morpheme._Tag.ValueType  # 13
        """주격 조사"""
        JKC: Morpheme._Tag.ValueType  # 9
        """보격 조사"""
        JKG: Morpheme._Tag.ValueType  # 10
        """관형격 조사"""
        JKO: Morpheme._Tag.ValueType  # 11
        """목적격 조사"""
        JKB: Morpheme._Tag.ValueType  # 8
        """부사격 조사"""
        JKV: Morpheme._Tag.ValueType  # 14
        """호격 조사"""
        JKQ: Morpheme._Tag.ValueType  # 12
        """인용격 조사"""
        JX: Morpheme._Tag.ValueType  # 15
        """보조사"""
        JC: Morpheme._Tag.ValueType  # 7
        """접속 조사"""
        EP: Morpheme._Tag.ValueType  # 3
        """선어말 어미"""
        EF: Morpheme._Tag.ValueType  # 2
        """종결 어미"""
        EC: Morpheme._Tag.ValueType  # 1
        """연결 어미"""
        ETN: Morpheme._Tag.ValueType  # 5
        """명사형 전성 어미"""
        ETM: Morpheme._Tag.ValueType  # 4
        """관형형 전성 어미"""
        XPN: Morpheme._Tag.ValueType  # 43
        """체언 접두사"""
        XSN: Morpheme._Tag.ValueType  # 46
        """명사 파생 접미사"""
        XSV: Morpheme._Tag.ValueType  # 47
        """동사 파생 접미사"""
        XSA: Morpheme._Tag.ValueType  # 45
        """형용사 파생 접미사"""
        XR: Morpheme._Tag.ValueType  # 44
        """어근"""
        SF: Morpheme._Tag.ValueType  # 30
        """마침표,물음표,느낌표"""
        SP: Morpheme._Tag.ValueType  # 35
        """쉼표,가운뎃점,콜론,빗금"""
        SS: Morpheme._Tag.ValueType  # 36
        """따옴표,괄호표,줄표"""
        SE: Morpheme._Tag.ValueType  # 29
        """줄임표"""
        SO: Morpheme._Tag.ValueType  # 34
        """붙임표(물결,숨김,빠짐)"""
        SW: Morpheme._Tag.ValueType  # 37
        """기타기호 (논리수학기호,화폐기호)"""
        SL: Morpheme._Tag.ValueType  # 32
        """외국어"""
        SH: Morpheme._Tag.ValueType  # 31
        """한자"""
        SN: Morpheme._Tag.ValueType  # 33
        """숫자"""

    class Tag(_Tag, metaclass=_TagEnumTypeWrapper):
        """내부적으로 pred 된 형태소는 0~42까지 반환하지만,
        1~43까지 숫자로 쓰고, UNK은 0으로 바꾼다.
        """

    UNK: Morpheme.Tag.ValueType  # 0
    """// 0 1 EC
    // 1 2 EF
    // 2 3 EP
    // 3 4 ETM
    // 4 5 ETN
    // 5 6 IC
    // 6 7 JC
    // 7 8 JKB
    // 8 9 JKC
    // 9 10 JKG
    // 10 11 JKO
    // 11 12 JKQ
    // 12 13 JKS
    // 13 14 JKV
    // 14 15 JX
    // 15 16 MAG
    // 16 17 MAJ
    // 17 18 MMA
    // 18 19 MMD
    // 19 20 MMN
    // 20 21 NA
    // 21 22 NF
    // 22 23 NNB
    // 23 24 NNG
    // 24 25 NNP
    // 25 26 NP
    // 26 27 NR
    // 27 28 NV
    // 28 29 SE
    // 29 30 SF
    // 30 31 SH
    // 31 32 SL
    // 32 33 SN
    // 33 34 SO
    // 34 35 SP
    // 35 36 SS
    // 36 37 SW
    // 37 38 VA
    // 38 39 VCN
    // 39 40 VCP
    // 40 41 VV
    // 41 42 VX
    // 42 43 XPN
    // 43 44 XR
    // 44 45 XSA
    // 45 46 XSN
    // 46 47 XSV
    """
    NNG: Morpheme.Tag.ValueType  # 24
    """일반 명사"""
    NNP: Morpheme.Tag.ValueType  # 25
    """고유 명사"""
    NNB: Morpheme.Tag.ValueType  # 23
    """의존 명사"""
    NP: Morpheme.Tag.ValueType  # 26
    """대명사"""
    NR: Morpheme.Tag.ValueType  # 27
    """수사"""
    NF: Morpheme.Tag.ValueType  # 22
    """명사 추정 범주"""
    NA: Morpheme.Tag.ValueType  # 21
    """분석불능범주"""
    NV: Morpheme.Tag.ValueType  # 28
    """용언 추정 범주"""
    VV: Morpheme.Tag.ValueType  # 41
    """동사"""
    VA: Morpheme.Tag.ValueType  # 38
    """형용사"""
    VX: Morpheme.Tag.ValueType  # 42
    """보조 용언"""
    VCP: Morpheme.Tag.ValueType  # 40
    """긍정 지정사"""
    VCN: Morpheme.Tag.ValueType  # 39
    """부정 지정사"""
    MMA: Morpheme.Tag.ValueType  # 18
    """성상 관형사"""
    MMD: Morpheme.Tag.ValueType  # 19
    """지시 관형사"""
    MMN: Morpheme.Tag.ValueType  # 20
    """수 관형사"""
    MAG: Morpheme.Tag.ValueType  # 16
    """일반 부사"""
    MAJ: Morpheme.Tag.ValueType  # 17
    """접속 부사"""
    IC: Morpheme.Tag.ValueType  # 6
    """감탄사"""
    JKS: Morpheme.Tag.ValueType  # 13
    """주격 조사"""
    JKC: Morpheme.Tag.ValueType  # 9
    """보격 조사"""
    JKG: Morpheme.Tag.ValueType  # 10
    """관형격 조사"""
    JKO: Morpheme.Tag.ValueType  # 11
    """목적격 조사"""
    JKB: Morpheme.Tag.ValueType  # 8
    """부사격 조사"""
    JKV: Morpheme.Tag.ValueType  # 14
    """호격 조사"""
    JKQ: Morpheme.Tag.ValueType  # 12
    """인용격 조사"""
    JX: Morpheme.Tag.ValueType  # 15
    """보조사"""
    JC: Morpheme.Tag.ValueType  # 7
    """접속 조사"""
    EP: Morpheme.Tag.ValueType  # 3
    """선어말 어미"""
    EF: Morpheme.Tag.ValueType  # 2
    """종결 어미"""
    EC: Morpheme.Tag.ValueType  # 1
    """연결 어미"""
    ETN: Morpheme.Tag.ValueType  # 5
    """명사형 전성 어미"""
    ETM: Morpheme.Tag.ValueType  # 4
    """관형형 전성 어미"""
    XPN: Morpheme.Tag.ValueType  # 43
    """체언 접두사"""
    XSN: Morpheme.Tag.ValueType  # 46
    """명사 파생 접미사"""
    XSV: Morpheme.Tag.ValueType  # 47
    """동사 파생 접미사"""
    XSA: Morpheme.Tag.ValueType  # 45
    """형용사 파생 접미사"""
    XR: Morpheme.Tag.ValueType  # 44
    """어근"""
    SF: Morpheme.Tag.ValueType  # 30
    """마침표,물음표,느낌표"""
    SP: Morpheme.Tag.ValueType  # 35
    """쉼표,가운뎃점,콜론,빗금"""
    SS: Morpheme.Tag.ValueType  # 36
    """따옴표,괄호표,줄표"""
    SE: Morpheme.Tag.ValueType  # 29
    """줄임표"""
    SO: Morpheme.Tag.ValueType  # 34
    """붙임표(물결,숨김,빠짐)"""
    SW: Morpheme.Tag.ValueType  # 37
    """기타기호 (논리수학기호,화폐기호)"""
    SL: Morpheme.Tag.ValueType  # 32
    """외국어"""
    SH: Morpheme.Tag.ValueType  # 31
    """한자"""
    SN: Morpheme.Tag.ValueType  # 33
    """숫자"""

    TEXT_FIELD_NUMBER: builtins.int
    TAG_FIELD_NUMBER: builtins.int
    PROBABILITY_FIELD_NUMBER: builtins.int
    OUT_OF_VOCAB_FIELD_NUMBER: builtins.int
    @property
    def text(self) -> global___TextSpan:
        """The sentence text."""
    tag: global___Morpheme.Tag.ValueType
    """형태소 태그"""
    probability: builtins.float
    """형태소 분석 결과 확률"""
    out_of_vocab: global___Morpheme.OutOfVocab.ValueType
    """유의어 번호
    int32 disambiguation = 4;

    사전에 없는 단어 표시
    """
    def __init__(
        self,
        *,
        text: global___TextSpan | None = ...,
        tag: global___Morpheme.Tag.ValueType = ...,
        probability: builtins.float = ...,
        out_of_vocab: global___Morpheme.OutOfVocab.ValueType = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["text", b"text"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["out_of_vocab", b"out_of_vocab", "probability", b"probability", "tag", b"tag", "text", b"text"]) -> None: ...

global___Morpheme = Morpheme

class Token(google.protobuf.message.Message):
    """어절"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TEXT_FIELD_NUMBER: builtins.int
    MORPHEMES_FIELD_NUMBER: builtins.int
    LEMMA_FIELD_NUMBER: builtins.int
    TAGGED_FIELD_NUMBER: builtins.int
    MODIFIED_FIELD_NUMBER: builtins.int
    @property
    def text(self) -> global___TextSpan:
        """The token text."""
    @property
    def morphemes(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Morpheme]:
        """어절 내부의 형태소 분리"""
    lemma: builtins.str
    """원형
    [Lemma](https://en.wikipedia.org/wiki/Lemma_%28morphology%29) of the token.
    """
    tagged: builtins.str
    """테그 문자열"""
    modified: builtins.str
    """원래의 값과 다른 내용이 있으면 modified에 값을 넣는다."""
    def __init__(
        self,
        *,
        text: global___TextSpan | None = ...,
        morphemes: collections.abc.Iterable[global___Morpheme] | None = ...,
        lemma: builtins.str = ...,
        tagged: builtins.str = ...,
        modified: builtins.str = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["text", b"text"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["lemma", b"lemma", "modified", b"modified", "morphemes", b"morphemes", "tagged", b"tagged", "text", b"text"]) -> None: ...

global___Token = Token

class TextSpan(google.protobuf.message.Message):
    """텍스트 조각"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    CONTENT_FIELD_NUMBER: builtins.int
    BEGIN_OFFSET_FIELD_NUMBER: builtins.int
    LENGTH_FIELD_NUMBER: builtins.int
    content: builtins.str
    """텍스트 조각의 내용"""
    begin_offset: builtins.int
    """텍스트 조각의 위치
    EncodingType에 따라서 위치의 값이 달라진다.
    """
    length: builtins.int
    """길이"""
    def __init__(
        self,
        *,
        content: builtins.str = ...,
        begin_offset: builtins.int = ...,
        length: builtins.int = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["begin_offset", b"begin_offset", "content", b"content", "length", b"length"]) -> None: ...

global___TextSpan = TextSpan

class AnalyzeSyntaxRequest(google.protobuf.message.Message):
    """형태소 분석 요청 메시지"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DOCUMENT_FIELD_NUMBER: builtins.int
    ENCODING_TYPE_FIELD_NUMBER: builtins.int
    AUTO_SPLIT_SENTENCE_FIELD_NUMBER: builtins.int
    CUSTOM_DOMAIN_FIELD_NUMBER: builtins.int
    AUTO_SPACING_FIELD_NUMBER: builtins.int
    AUTO_JOINTING_FIELD_NUMBER: builtins.int
    @property
    def document(self) -> global___Document:
        """입력 문서"""
    encoding_type: global___EncodingType.ValueType
    """오프셋을 계산하기 위한 인코딩 타입"""
    auto_split_sentence: builtins.bool
    """auto split sentence true이면 자동으로 문장 분리를 시도한다.
    없으면 \\n 을 기준으로 문장을 자른다.
    기본값은 false 이다.
    """
    custom_domain: builtins.str
    """커스텀 사전 도메인 정보
    고유명사, 복합명사 사전에 기반하여 처리함.
    """
    auto_spacing: builtins.bool
    """자동 띄어쓰기"""
    auto_jointing: builtins.bool
    """자동 붙여쓰기"""
    def __init__(
        self,
        *,
        document: global___Document | None = ...,
        encoding_type: global___EncodingType.ValueType = ...,
        auto_split_sentence: builtins.bool = ...,
        custom_domain: builtins.str = ...,
        auto_spacing: builtins.bool = ...,
        auto_jointing: builtins.bool = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["document", b"document"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["auto_jointing", b"auto_jointing", "auto_spacing", b"auto_spacing", "auto_split_sentence", b"auto_split_sentence", "custom_domain", b"custom_domain", "document", b"document", "encoding_type", b"encoding_type"]) -> None: ...

global___AnalyzeSyntaxRequest = AnalyzeSyntaxRequest

class AnalyzeSyntaxResponse(google.protobuf.message.Message):
    """형태 분석 응담 메시지"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SENTENCES_FIELD_NUMBER: builtins.int
    LANGUAGE_FIELD_NUMBER: builtins.int
    @property
    def sentences(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Sentence]:
        """입력된 문장에 포함된 문장들"""
    language: builtins.str
    """텍스트의 언어, 만일 언어가 지정되지 않은 경우에는 자돋으로 탐지하여 반환한다.
    언어가 지정된 경우에는 동일한 언어를 반환한다.
    이때, 언어는 ko_KR 등과 같이 사용한다.
    """
    def __init__(
        self,
        *,
        sentences: collections.abc.Iterable[global___Sentence] | None = ...,
        language: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["language", b"language", "sentences", b"sentences"]) -> None: ...

global___AnalyzeSyntaxResponse = AnalyzeSyntaxResponse

class AnalyzeSyntaxListRequest(google.protobuf.message.Message):
    """형태소 분석 요청 메시지"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SENTENCES_FIELD_NUMBER: builtins.int
    LANGUAGE_FIELD_NUMBER: builtins.int
    ENCODING_TYPE_FIELD_NUMBER: builtins.int
    CUSTOM_DOMAIN_FIELD_NUMBER: builtins.int
    AUTO_SPACING_FIELD_NUMBER: builtins.int
    AUTO_JOINTING_FIELD_NUMBER: builtins.int
    @property
    def sentences(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
        """입력 문장의 배열"""
    language: builtins.str
    """입력 문장의 언어"""
    encoding_type: global___EncodingType.ValueType
    """오프셋을 계산하기 위한 인코딩 타입"""
    custom_domain: builtins.str
    """커스텀 사전 도메인 정보
    고유명사, 복합명사 사전에 기반하여 처리함.
    """
    auto_spacing: builtins.bool
    """자동 띄어쓰기"""
    auto_jointing: builtins.bool
    """자동 붙여쓰기"""
    def __init__(
        self,
        *,
        sentences: collections.abc.Iterable[builtins.str] | None = ...,
        language: builtins.str = ...,
        encoding_type: global___EncodingType.ValueType = ...,
        custom_domain: builtins.str = ...,
        auto_spacing: builtins.bool = ...,
        auto_jointing: builtins.bool = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["auto_jointing", b"auto_jointing", "auto_spacing", b"auto_spacing", "custom_domain", b"custom_domain", "encoding_type", b"encoding_type", "language", b"language", "sentences", b"sentences"]) -> None: ...

global___AnalyzeSyntaxListRequest = AnalyzeSyntaxListRequest

class AnalyzeSyntaxListResponse(google.protobuf.message.Message):
    """형태 분석 응담 메시지"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SENTENCES_FIELD_NUMBER: builtins.int
    LANGUAGE_FIELD_NUMBER: builtins.int
    @property
    def sentences(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Sentence]:
        """입력된 문장에 포함된 문장들
        여기서 문장은 요청에 대응하여 1:1로 맞춰진다.
        만일 요청이 빈 문장이면 빈 문장으로 대응한다.
        """
    language: builtins.str
    """텍스트의 언어, 만일 언어가 지정되지 않은 경우에는 자돋으로 탐지하여 반환한다.
    언어가 지정된 경우에는 동일한 언어를 반환한다.
    이때, 언어는 ko_KR 등과 같이 사용한다.
    """
    def __init__(
        self,
        *,
        sentences: collections.abc.Iterable[global___Sentence] | None = ...,
        language: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["language", b"language", "sentences", b"sentences"]) -> None: ...

global___AnalyzeSyntaxListResponse = AnalyzeSyntaxListResponse

class TokenizeRequest(google.protobuf.message.Message):
    """토크나이즈 요청 메시지"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DOCUMENT_FIELD_NUMBER: builtins.int
    ENCODING_TYPE_FIELD_NUMBER: builtins.int
    AUTO_SPLIT_SENTENCE_FIELD_NUMBER: builtins.int
    AUTO_SPACING_FIELD_NUMBER: builtins.int
    @property
    def document(self) -> global___Document:
        """Input document."""
    encoding_type: global___EncodingType.ValueType
    """The encoding type used by the API to calculate offsets."""
    auto_split_sentence: builtins.bool
    """auto split sentence true이면 자동으로 문장 분리를 시도한다.
    없으면 \\n 을 기준으로 문장을 자른다.
    기본값은 false 이다.
    """
    auto_spacing: builtins.bool
    """자동 띄어쓰기"""
    def __init__(
        self,
        *,
        document: global___Document | None = ...,
        encoding_type: global___EncodingType.ValueType = ...,
        auto_split_sentence: builtins.bool = ...,
        auto_spacing: builtins.bool = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["document", b"document"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["auto_spacing", b"auto_spacing", "auto_split_sentence", b"auto_split_sentence", "document", b"document", "encoding_type", b"encoding_type"]) -> None: ...

global___TokenizeRequest = TokenizeRequest

class Segment(google.protobuf.message.Message):
    """토큰의 분절된 내용"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TEXT_FIELD_NUMBER: builtins.int
    HINT_FIELD_NUMBER: builtins.int
    @property
    def text(self) -> global___TextSpan:
        """The token text."""
    hint: builtins.str
    """각 위치에 대한 정보"""
    def __init__(
        self,
        *,
        text: global___TextSpan | None = ...,
        hint: builtins.str = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["text", b"text"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["hint", b"hint", "text", b"text"]) -> None: ...

global___Segment = Segment

class SegmentToken(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TEXT_FIELD_NUMBER: builtins.int
    SEGMENTS_FIELD_NUMBER: builtins.int
    TAGGED_FIELD_NUMBER: builtins.int
    @property
    def text(self) -> global___TextSpan:
        """The token text."""
    @property
    def segments(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Segment]:
        """어절 내부의 형태소 분리"""
    tagged: builtins.str
    """아름답/V+ㄴ/E"""
    def __init__(
        self,
        *,
        text: global___TextSpan | None = ...,
        segments: collections.abc.Iterable[global___Segment] | None = ...,
        tagged: builtins.str = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["text", b"text"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["segments", b"segments", "tagged", b"tagged", "text", b"text"]) -> None: ...

global___SegmentToken = SegmentToken

class SegmentSentence(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TEXT_FIELD_NUMBER: builtins.int
    TOKENS_FIELD_NUMBER: builtins.int
    @property
    def text(self) -> global___TextSpan:
        """The token text."""
    @property
    def tokens(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___SegmentToken]:
        """어절 내부의 형태소 분리"""
    def __init__(
        self,
        *,
        text: global___TextSpan | None = ...,
        tokens: collections.abc.Iterable[global___SegmentToken] | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["text", b"text"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["text", b"text", "tokens", b"tokens"]) -> None: ...

global___SegmentSentence = SegmentSentence

class TokenizeResponse(google.protobuf.message.Message):
    """Tokenize 요청 토크나이즈에 대한 요청"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SENTENCES_FIELD_NUMBER: builtins.int
    LANGUAGE_FIELD_NUMBER: builtins.int
    @property
    def sentences(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___SegmentSentence]:
        """분절 분리된 문장들의 배열"""
    language: builtins.str
    """ISO 문자 코드"""
    def __init__(
        self,
        *,
        sentences: collections.abc.Iterable[global___SegmentSentence] | None = ...,
        language: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["language", b"language", "sentences", b"sentences"]) -> None: ...

global___TokenizeResponse = TokenizeResponse
